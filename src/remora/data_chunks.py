from collections import defaultdict

from taiyaki.mapped_signal_files import MappedSignalReader

from remora import log

LOGGER = log.get_logger()

# TODO convert module to be a batch generator


def load_chunks(
    dataset_path,
    num_chunks,
    mod,
    focus_offset,
    chunk_context,
    fixed_seq_len_chunks=False,
    base_pred=False,
):
    """
    Args:
        dataset_path: path to a hdf5 file generated by extract_toy_dataset
        num_chunks: size of returned dataset in number of instances
        mod: modified base single letter code
        focus_offset: index of (mod)base in reference
        chunk_context: 2-tuple containing context signal or bases for each
            chunk
        fixed_seq_len_chunks: return chunks with fixed sequence length and
            variable signal length. Default returns chunks with fixed signal
            length and variable length sequences.

    Returns:
        sigs: list of signal chunks
        labels: list of mod/unmod labels for the corresponding chunks
        refs: list of reference sequences for each chunk
        base_locs: location for each base in the corersponing chunk
    """

    # TODO include a padding option

    read_data = MappedSignalReader(dataset_path)
    n_reads = len(read_data.get_read_ids())
    if num_chunks is None or num_chunks == 0 or num_chunks > n_reads:
        num_chunks = n_reads
    if not isinstance(num_chunks, int):
        raise ValueError("num_chunks must be an integer")
    if len(chunk_context) != 2:
        raise ValueError("chunk_context must be length 2")
    if any(not isinstance(cc, int) for cc in chunk_context):
        raise ValueError("chunk_context must be integers")

    # TODO allow multiple modified bases
    alphabet_info = read_data.get_alphabet_information()

    if base_pred:
        if alphabet_info.alphabet != "ACGT":
            raise ValueError("Alphabet is not canonical.")

    mod_idx = alphabet_info.alphabet.find(mod)

    sigs = []
    labels = []
    refs = []
    base_locations = []
    read_ids = []
    positions = []

    reject_reasons = defaultdict(int)
    for read in read_data:

        sig = read.get_current(read.get_mapped_dacs_region())
        # TODO actually grab correct region of reference
        # probably also 1-hot encode
        ref = "".join(
            alphabet_info.collapse_alphabet[b] for b in read.Reference
        )
        base_locs = read.Ref_to_signal - read.Ref_to_signal[0]
        if base_pred:
            label = read.Reference[focus_offset]
        else:
            label = int(read.Reference[focus_offset] == mod_idx)

        if fixed_seq_len_chunks:
            base_start = focus_offset - chunk_context[0]
            base_end = focus_offset + chunk_context[1] + 1
            if base_start <= 0:
                reject_reasons["invalid_base_start"] += 1
                continue
            if base_end >= len(base_locs):
                reject_reasons["invalid_base_end"] += 1
                continue
            sig_start = base_locs[base_start]
            sig_end = base_locs[base_end]
        else:
            # compute position at center of central base
            center_loc = (
                base_locs[focus_offset] + base_locs[focus_offset + 1]
            ) // 2
            sig_start = center_loc - chunk_context[0]
            sig_end = center_loc + chunk_context[1]
            if sig_start < 0:
                reject_reasons["invalid_signal_start"] += 1
                continue
            if sig_end > base_locs[-1]:
                reject_reasons["invalid_signal_end"] += 1
                continue

        sigs.append(sig[sig_start:sig_end])
        labels.append(label)
        refs.append(ref)
        base_locations.append(base_locs)
        read_ids.append(read.read_id)
        positions.append(read.Ref_to_signal[focus_offset])

        reject_reasons["success"] += 1
        if reject_reasons["success"] >= num_chunks:
            break

    rej_summ = "\n".join(
        f"\t{count}\t{reason}"
        for count, reason in sorted(
            (count, reason) for reason, count in reject_reasons.items()
        )
    )
    LOGGER.info(f"Chunk selection summary:\n{rej_summ}\n")

    return sigs, labels, refs, base_locations, read_ids, positions
